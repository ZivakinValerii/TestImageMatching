{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e76f21-84c5-497b-ba06-50dd4e14c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Так, як тільки я побачив тему завдання я вже на 80 відсодків був впевнений, що буду використовувати саме пошук особливих точок\n",
    "# Окрім них, мені в голову прийшло ще два варіанти - навчання ШІ по типу сіамської, яка як раз для цього і придумана (наскільки я знаю) \n",
    "# і статистичний аналіз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f5f25c-3168-45be-9633-06ff291cba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Швидкий гугл-пошук плюс чат-ГПТ, в принципі, підтвердили мою першу думку- левова частка статей, які я знайшов, стотувалися \n",
    "# особливих точок, декілька були про deep learning, а про статистику взагалі загадав ГПТ і то не у першу чергу.\n",
    "# Додам, що я ще вагався між варіантом із нейромережею і фічами, бо було заявлено 16 гб відеопам'яті і по суті - дан датасет,\n",
    "# але розбиратися із тим як саме все заанотувати і віддати на навчання - довго. Плюс, ніхто не писав, що його саме так можна використати.\n",
    "# А в мене вже визрівала ідея."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0964533f-da2e-42cd-ac19-2b8615f68c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Спочатку ідея здавалась мені досить простою. Хоч я колись вже займався саме склейкою зображень по особливих точках, мені здавалось,\n",
    "# що можна придумати досить просте рішення на кшталт відношення знайдених співпадінь по особливих точкаж до їхньої кількості на одному із зображень.\n",
    "# Виглядало просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee6b609-22fa-4456-a4b9-af2ae2632149",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch_images\u001b[39m(image1_path, image2_path, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORB\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      4\u001b[0m     image1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image1_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def match_images(image1_path, image2_path, algorithm='ORB'):\n",
    "    image1 = cv2.imread(image1_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image2 = cv2.imread(image2_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if algorithm == 'ORB':\n",
    "        detector = cv2.ORB_create()\n",
    "    elif algorithm == 'SURF':\n",
    "        detector = cv2.xfeatures2d.SURF_create()\n",
    "\n",
    "    keypoints1, descriptors1 = detector.detectAndCompute(image1, None)\n",
    "    keypoints2, descriptors2 = detector.detectAndCompute(image2, None)\n",
    "\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    matches = matcher.match(descriptors1, descriptors2)\n",
    "\n",
    "    similarity = len(matches) / max(len(keypoints1), len(keypoints2))\n",
    "\n",
    "    return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce25d9b-4091-4c6a-be31-ad8a8dcb37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут я ще не використовув Sift, бо пам'ятав, що він досить повільний, хоча йому і можна обмежети кількість фічей для пошуку.\n",
    "# Результат був зовсім не дуже, а тут завершився вечір середи (день отримання завдання)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be272a7-20bd-4b8b-8e71-077c34373d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вже ввечері четверга, коли з'явився час я продовжив роздуми. Для початку використав інші детектори і також спробував побудувати відношення \n",
    "# так званих \"хороших\" співпадінь фічей до усіх (ту весрію я видалив тому схематично обріжу фінальний варіант)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee857d41-24f8-4282-b710-551fddb5bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_two_images(image1_path, image2_path, detector_type, match_threshold, good_matches_threshold,\n",
    "                       acceptable_rotation_angle, show_result: bool):\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "    if detector_type == 'Akaze':\n",
    "        detector = cv2.AKAZE_create()\n",
    "    elif detector_type == 'Sift':\n",
    "        detector = cv2.SIFT_create()\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY) # sometimes gray scale could be better\n",
    "    kp1, descriptors1 = detector.detectAndCompute(image1, None)  # kp = keypoints\n",
    "\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    kp2, descriptors2 = detector.detectAndCompute(image2, None)\n",
    "\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(descriptors2, descriptors1, k=2)\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < match_threshold * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "   \n",
    "    return len(good)/len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d22f93ba-f71c-42c8-b776-0ac1f63383a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Результат був теж так собі. І з рештою я дійшов до того, що мені потрібно оцінити,\n",
    "# чи зміг бі я вписати одне зображення в інше(точніше, яку його частку). Так я і прийшов до того, що треба вигадати оцінку \n",
    "# розмірів \"склеїного\" зображення відносно максимальних вхідних. Але з уточненнями:\n",
    "# по-перше: достатня кількість \"хороших\" співпадань фічей (якщо їх мало - зображення точно різні)\n",
    "# по-друге: інколи (навіть часто) детектори можуть знайти хороші співпадіння навіть на різних зображеннях\n",
    "#   але розміщення їх буде таке, що одне зображення перекрутить, тому треба обмежувати кут повороту як мінімум по Z-складовій\n",
    "#   (30 градусів можливо навіть завеликий)\n",
    "# До самого відношення також дійшов сам- було декілька варіантв, останнє здалося найкрасивішим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463e4404-4ddc-4f29-857c-06c2c0be46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Про переваги: відсутнє анотування і навчання, метод можна одразу використовувати\n",
    "# Якщо розміри +- співставні можна давати йому на вхід практично будь-що. Без довизначення класів, кластерів і тд.\n",
    "# Доволі таки не сильно потребує потужностой - все виконується на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ae154-a2c6-4ef0-8045-df6e4644a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Головний недолік напевно те, що працює відносно повільно. Загалом за рахунок довгого відпрацювання детекторів. \n",
    "# Але можна спробувати модифікувати. Загалом все, дякую"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
